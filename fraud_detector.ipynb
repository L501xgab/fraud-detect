{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "suspended-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use(style = 'seaborn')\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## DATA IMPORT ## \n",
    "\n",
    "data_path = \"./data/\"\n",
    "\n",
    "train_tr = pd.read_csv(data_path + \"train_transaction.csv\")\n",
    "train_id = pd.read_csv(data_path + \"train_identity.csv\") \n",
    "test_tr = pd.read_csv(data_path + \"test_transaction.csv\")\n",
    "test_id = pd.read_csv(data_path + \"test_identity.csv\")\n",
    "\n",
    "print('train_transaction shape is {}'.format(train_tr.shape))\n",
    "print('train_identity shape is {}'.format(train_id.shape))\n",
    "\n",
    "print('test_transaction shape is {}'.format(test_tr.shape))\n",
    "print('test_identity shape is {}'.format(test_id.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08439a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fecbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cbe946",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train_tr, train_id, how = 'left', on = 'TransactionID')\n",
    "test = pd.merge(test_tr, test_id, how = 'left', on = 'TransactionID')\n",
    "del train_tr, train_id, test_tr, test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974efe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae347be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55263cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6d9da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def different_columns(traincols, testcols):\n",
    "    \n",
    "    for i in traincols:\n",
    "        \n",
    "        if i not in testcols:\n",
    "            \n",
    "            print(i)\n",
    "            \n",
    "different_columns(train.columns, test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.rename(columns = {\"id-01\": \"id_01\", \"id-02\": \"id_02\", \"id-03\": \"id_03\", \n",
    "                            \"id-06\": \"id_06\", \"id-05\": \"id_05\", \"id-04\": \"id_04\", \n",
    "                            \"id-07\": \"id_07\", \"id-08\": \"id_08\", \"id-09\": \"id_09\", \n",
    "                            \"id-10\": \"id_10\", \"id-11\": \"id_11\", \"id-12\": \"id_12\", \n",
    "                            \"id-15\": \"id_15\", \"id-14\": \"id_14\", \"id-13\": \"id_13\", \n",
    "                            \"id-16\": \"id_16\", \"id-17\": \"id_17\", \"id-18\": \"id_18\", \n",
    "                            \"id-21\": \"id_21\", \"id-20\": \"id_20\", \"id-19\": \"id_19\", \n",
    "                            \"id-22\": \"id_22\", \"id-23\": \"id_23\", \"id-24\": \"id_24\", \n",
    "                            \"id-27\": \"id_27\", \"id-26\": \"id_26\", \"id-25\": \"id_25\", \n",
    "                            \"id-28\": \"id_28\", \"id-29\": \"id_29\", \"id-30\": \"id_30\", \n",
    "                            \"id-31\": \"id_31\", \"id-32\": \"id_32\", \"id-33\": \"id_33\", \n",
    "                            \"id-34\": \"id_34\", \"id-35\": \"id_35\", \"id-36\": \"id_36\", \n",
    "                            \"id-37\": \"id_37\", \"id-38\": \"id_38\"})\n",
    "\n",
    "different_columns(train.columns, test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f356bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (5, 5))\n",
    "\n",
    "sns.barplot([0,1],train['isFraud'].value_counts().values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124991fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_ratio = train['isFraud'].sum()/len(train['isFraud'])\n",
    "print(fraud_ratio)\n",
    "del fraud_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be562d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_missing_value = train.isnull().sum().sum()\n",
    "print(tot_missing_value)\n",
    "del tot_missing_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479f40ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_missing_value = train.isnull().sum()\n",
    "print(column_missing_value[0 : 60])\n",
    "print(column_missing_value[60 : 120])\n",
    "print(column_missing_value[120 : 180])\n",
    "print(column_missing_value[180 : 240])\n",
    "print(column_missing_value[240 : 300])\n",
    "print(column_missing_value[300 : 360])\n",
    "print(column_missing_value[360 : 420])\n",
    "print(column_missing_value[420 : 434])\n",
    "del column_missing_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3bf479",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot dates of transaction. they don't overlap ##\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "plt.hist(train['TransactionDT'], label = 'Train', bins = 35, color = 'red')\n",
    "plt.hist(test['TransactionDT'], label = 'Test', bins = 35, color = 'yellow')\n",
    "plt.legend()\n",
    "plt.title('Train vs. Test TransactionDT Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bad65ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## ENCODING VARIABLES\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "variables_train = train.keys()\n",
    "for k in variables_train:\n",
    "    if train[k].dtype == object:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        train[k + '_encoded'] = le.fit_transform(train[k])  \n",
    "        train = train.drop([k], axis=1)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff67e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNBALANCED APPROACH - DT\n",
    "\n",
    "X = train.copy()\n",
    "y = train['isFraud'].copy()\n",
    "X = X.drop(['isFraud'], axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create our imputer to replace missing values with the mean e.g.\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp = imp.fit(X_train)\n",
    "\n",
    "# Impute our data, then train\n",
    "X_train_imp = imp.transform(X_train)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_model = DecisionTreeClassifier(criterion=\"gini\", random_state=17,max_depth=100, min_samples_leaf=50)   \n",
    "clf_model.fit(X_train_imp,y_train)\n",
    "y_pred = []\n",
    "X_test_imp = imp.transform(X_test)\n",
    "y_pred = clf_model.predict(X_test_imp)\n",
    "y_train_pred = clf_model.predict(X_train_imp)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print('Unbalanced DT - train precision score is {}'.format(precision_score(y_train, y_train_pred)))\n",
    "print('Unbalanced DT - train accuracy score is {}'.format(accuracy_score(y_train, y_train_pred)))\n",
    "print('Unbalanced DT - train recall score is {}'.format(recall_score(y_train, y_train_pred)))\n",
    "print('Unbalanced DT - train auc score is {}'.format(roc_auc_score(y_train, y_train_pred)))\n",
    "\n",
    "print('Unbalanced DT - test precision score is {}'.format(precision_score(y_test, y_pred)))\n",
    "print('Unbalanced DT - test accuracy score is {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Unbalanced DT - test recall score is {}'.format(recall_score(y_test, y_pred)))\n",
    "print('Unbalanced DT - test auc score is {}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2a9439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNBALANCED APPROACH - XGBOOST\n",
    "\n",
    "xgmodel = xgb.XGBClassifier(n_estimators = 100,\n",
    "                            max_depth = 12,\n",
    "                            learning_rate = 0.02,\n",
    "                            subsample = 0.8,\n",
    "                            colsample_bytree = 0.4,\n",
    "                            missing = -1,\n",
    "                            random_state = 42,\n",
    "                            tree_method = 'gpu_hist')\n",
    "xgmodel.fit(X_train_imp,y_train)\n",
    "\n",
    "y_pred = []\n",
    "X_test_imp = imp.transform(X_test)\n",
    "y_pred = xgmodel.predict(X_test_imp)\n",
    "y_train_pred = xgmodel.predict(X_train_imp)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print('Unbalanced XGB - train precision score is {}'.format(precision_score(y_train, y_train_pred)))\n",
    "print('Unbalanced XGB - train accuracy score is {}'.format(accuracy_score(y_train, y_train_pred)))\n",
    "print('Unbalanced XGB - train recall score is {}'.format(recall_score(y_train, y_train_pred)))\n",
    "print('Unbalanced XGB - train auc score is {}'.format(roc_auc_score(y_train, y_train_pred)))\n",
    "\n",
    "print('Unbalanced XGB - test precision score is {}'.format(precision_score(y_test, y_pred)))\n",
    "print('Unbalanced XGB - test accuracy score is {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Unbalanced XGB - test recall score is {}'.format(recall_score(y_test, y_pred)))\n",
    "print('Unbalanced XGB - test auc score is {}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cdeb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## UNDERSAMPLING APPROACH - DT\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "ros = RandomUnderSampler(random_state=17)\n",
    "X = train.copy()\n",
    "y = train['isFraud'].copy()\n",
    "X = X.drop(['isFraud'], axis=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_resampled)))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=17)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create our imputer to replace missing values with the mean e.g.\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp = imp.fit(X_train)\n",
    "\n",
    "# Impute our data, then train\n",
    "X_train_imp = imp.transform(X_train)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_model = DecisionTreeClassifier(criterion=\"gini\", random_state=17,max_depth=100, min_samples_leaf=5)   \n",
    "clf_model.fit(X_train_imp,y_train)\n",
    "y_pred = []\n",
    "X_test_imp = imp.transform(X_test)\n",
    "y_pred = clf_model.predict(X_test_imp)\n",
    "y_train_pred = clf_model.predict(X_train_imp)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print('Undersampled DT - train precision score is {}'.format(precision_score(y_train, y_train_pred)))\n",
    "print('Undersampled DT - train accuracy score is {}'.format(accuracy_score(y_train, y_train_pred)))\n",
    "print('Undersampled DT - train recall score is {}'.format(recall_score(y_train, y_train_pred)))\n",
    "print('Undersampled DT - train auc score is {}'.format(roc_auc_score(y_train, y_train_pred)))\n",
    "\n",
    "print('Undersampled DT - test precision score is {}'.format(precision_score(y_test, y_pred)))\n",
    "print('Undersampled DT - test accuracy score is {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Undersampled DT - test recall score is {}'.format(recall_score(y_test, y_pred)))\n",
    "print('Undersampled DT - test auc score is {}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f49d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## UNDERSAMPLING APPROACH - XGBOOST\n",
    "\n",
    "xgmodel = xgb.XGBClassifier(n_estimators = 100,\n",
    "                            max_depth = 12,\n",
    "                            learning_rate = 0.02,\n",
    "                            subsample = 0.8,\n",
    "                            colsample_bytree = 0.4,\n",
    "                            missing = -1,\n",
    "                            random_state = 42,\n",
    "                            tree_method = 'gpu_hist')\n",
    "xgmodel.fit(X_train_imp,y_train)\n",
    "\n",
    "y_pred = []\n",
    "X_test_imp = imp.transform(X_test)\n",
    "y_pred = xgmodel.predict(X_test_imp)\n",
    "y_train_pred = xgmodel.predict(X_train_imp)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print('Undersampled XGB - train precision score is {}'.format(precision_score(y_train, y_train_pred)))\n",
    "print('Undersampled XGB - train accuracy score is {}'.format(accuracy_score(y_train, y_train_pred)))\n",
    "print('Undersampled XGB - train recall score is {}'.format(recall_score(y_train, y_train_pred)))\n",
    "print('Undersampled XGB - train auc score is {}'.format(roc_auc_score(y_train, y_train_pred)))\n",
    "\n",
    "print('Undersampled XGB - test precision score is {}'.format(precision_score(y_test, y_pred)))\n",
    "print('Undersampled XGB - test accuracy score is {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Undersampled XGB - test recall score is {}'.format(recall_score(y_test, y_pred)))\n",
    "print('Undersampled XGB - test auc score is {}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f1e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OVERSAMPLING APPROACH - DT\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "ros = RandomOverSampler(random_state=17)\n",
    "X = train.copy()\n",
    "y = train['isFraud'].copy()\n",
    "X = X.drop(['isFraud'], axis=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_resampled)))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=17)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create our imputer to replace missing values with the mean e.g.\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp = imp.fit(X_train)\n",
    "\n",
    "# Impute our data, then train\n",
    "X_train_imp = imp.transform(X_train)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_model = DecisionTreeClassifier(criterion=\"gini\", random_state=17,max_depth=100, min_samples_leaf=50)   \n",
    "clf_model.fit(X_train_imp,y_train)\n",
    "y_pred = []\n",
    "X_test_imp = imp.transform(X_test)\n",
    "y_pred = clf_model.predict(X_test_imp)\n",
    "y_train_pred = clf_model.predict(X_train_imp)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print('Oversampled DT - train precision score is {}'.format(precision_score(y_train, y_train_pred)))\n",
    "print('Oversampled DT - train accuracy score is {}'.format(accuracy_score(y_train, y_train_pred)))\n",
    "print('Oversampled DT - train recall score is {}'.format(recall_score(y_train, y_train_pred)))\n",
    "print('Oversampled DT - train auc score is {}'.format(roc_auc_score(y_train, y_train_pred)))\n",
    "\n",
    "print('Oversampled DT - test precision score is {}'.format(precision_score(y_test, y_pred)))\n",
    "print('Oversampled DT - test accuracy score is {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Oversampled DT - test recall score is {}'.format(recall_score(y_test, y_pred)))\n",
    "print('Oversampled DT - test auc score is {}'.format(roc_auc_score(y_test, y_pred)))\n",
    "\n",
    "## OVERSAMPLING IS BETTER THAN UNDERSAMPLING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OVERSAMPLING APPROACH - XGBOOST\n",
    "\n",
    "xgmodel = xgb.XGBClassifier(n_estimators = 100,\n",
    "                            max_depth = 12,\n",
    "                            learning_rate = 0.02,\n",
    "                            subsample = 0.8,\n",
    "                            colsample_bytree = 0.4,\n",
    "                            missing = -1,\n",
    "                            random_state = 42,\n",
    "                            tree_method = 'gpu_hist')\n",
    "xgmodel.fit(X_train_imp,y_train)\n",
    "\n",
    "y_pred = []\n",
    "X_test_imp = imp.transform(X_test)\n",
    "y_pred = xgmodel.predict(X_test_imp)\n",
    "y_train_pred = xgmodel.predict(X_train_imp)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print('Oversampled XGB - train precision score is {}'.format(precision_score(y_train, y_train_pred)))\n",
    "print('Oversampled XGB - train accuracy score is {}'.format(accuracy_score(y_train, y_train_pred)))\n",
    "print('Oversampled XGB - train recall score is {}'.format(recall_score(y_train, y_train_pred)))\n",
    "print('Oversampled XGB - train auc score is {}'.format(roc_auc_score(y_train, y_train_pred)))\n",
    "\n",
    "print('Oversampled XGB - test precision score is {}'.format(precision_score(y_test, y_pred)))\n",
    "print('Oversampled XGB - test accuracy score is {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Oversampled XGB - test recall score is {}'.format(recall_score(y_test, y_pred)))\n",
    "print('Oversampled XGB - test auc score is {}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c51280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#clf_model = DecisionTreeClassifier(criterion=\"gini\")\n",
    "#distrib = dict(max_depth = [10,100,500], min_samples_leaf=[5,10,20,50])\n",
    "#clf = RandomizedSearchCV(clf_model, distrib, random_state=17)\n",
    "#search = clf.fit(X_train_imp,y_train)\n",
    "#search.best_params_\n",
    "\n",
    "# search of best params output - {'min_samples_leaf': 5, 'max_depth': 500}\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#clf_model = RandomForestClassifier(max_depth=100, min_samples_leaf=50, n_estimators = 500)   \n",
    "#clf_model.fit(X_train_imp,y_train)\n",
    "#y_pred = []\n",
    "#X_test_imp = imp.transform(X_test)\n",
    "#y_pred = clf_model.predict(X_test_imp)\n",
    "\n",
    "\n",
    "#from sklearn.metrics import precision_score\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "#from sklearn.metrics import recall_score\n",
    "\n",
    "#print('precision score is {}'.format(precision_score(y_test, y_pred)))\n",
    "#print('accuracy score is {}'.format(accuracy_score(y_test, y_pred)))\n",
    "#print('recall score is {}'.format(recall_score(y_test, y_pred)))\n",
    "#print('auc score is {}'.format(roc_auc_score(y_test, y_pred)))\n",
    "\n",
    "# RANDOMFOREST RESULTS, 500 trees, max depth 100, min leaves 50\n",
    "# precision score is 0.9363672902660041\n",
    "# accuracy score is 0.9202065356151102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69322d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree_best_clf = DecisionTreeClassifier(criterion=\"gini\", \n",
    "#                                       max_depth = search.best_params_['max_depth'], \n",
    "#                                       min_samples_leaf = search.best_params_['min_samples_leaf'])\n",
    "\n",
    "tree_best_clf = DecisionTreeClassifier(criterion=\"gini\", \n",
    "                                       max_depth = 500, \n",
    "                                       min_samples_leaf = 5)\n",
    "\n",
    "tree_best_clf.fit(X_train_imp,y_train)\n",
    "X_test_imp = imp.transform(X_test)\n",
    "y_pred = tree_best_clf.predict(X_test_imp)\n",
    "y_train_pred = tree_best_clf.predict(X_train_imp)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print('Oversampled BESTDT - train precision score is {}'.format(precision_score(y_train, y_train_pred)))\n",
    "print('Oversampled BESTDT - train accuracy score is {}'.format(accuracy_score(y_train, y_train_pred)))\n",
    "print('Oversampled BESTDT - train recall score is {}'.format(recall_score(y_train, y_train_pred)))\n",
    "print('Oversampled BESTDT - train auc score is {}'.format(roc_auc_score(y_train, y_train_pred)))\n",
    "\n",
    "print('Oversampled BESTDT - test precision score is {}'.format(precision_score(y_test, y_pred)))\n",
    "print('Oversampled BESTDT - test accuracy score is {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Oversampled BESTDT - test recall score is {}'.format(recall_score(y_test, y_pred)))\n",
    "print('Oversampled BESTDT - test auc score is {}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c6c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MASSIVE ESTIMATORS XGB TRIAL - OVERSAMPLED APPROACH\n",
    "xgmodel = xgb.XGBClassifier(n_estimators = 100,\n",
    "                            max_depth = 12,\n",
    "                            learning_rate = 0.02,\n",
    "                            subsample = 0.8,\n",
    "                            colsample_bytree = 0.4,\n",
    "                            missing = -1,\n",
    "                            random_state = 42,\n",
    "                            tree_method = 'gpu_hist')\n",
    "xgmodel.fit(X_train_imp,y_train)\n",
    "\n",
    "y_pred = []\n",
    "X_test_imp = imp.transform(X_test)\n",
    "y_pred = xgmodel.predict(X_test_imp)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print('precision score is {}'.format(precision_score(y_test, y_pred)))\n",
    "print('accuracy score is {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('recall score is {}'.format(recall_score(y_test, y_pred)))\n",
    "print('auc score is {}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf2b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA ##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
